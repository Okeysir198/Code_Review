{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4ad83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "content: <think>\n",
      "Okay, the user said \"hello\". I need to respond appropriately. Since there's no specific query or request, just a greeting, I should reply with a friendly greeting. No need to use any tools here. Let me make sure the response is welcoming and offers assistance. Something like \"Hello! How can I assist you today?\" That should cover it.\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "tool_calls: []\n",
      "********************\n",
      "content: \n",
      "tool_calls: [{'name': 'tavily_search_results_json', 'args': {'query': \"today's temperature in Ho Chi Minh City\"}, 'id': '8d5c4aa4-17c6-407c-9835-7b97e0a5a863', 'type': 'tool_call'}]\n",
      "********************\n",
      "content: \n",
      "tool_calls: [{'name': 'perform_calculation', 'args': {'expression': '2 * 4 / 90'}, 'id': 'a660ef3c-0ccd-4847-ad13-298a6b183c83', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "def print_response(response):\n",
    "    print(\"*\"*20)\n",
    "    for k, v in response.__dict__.items():\n",
    "        if k =='content' or k == 'tool_calls':\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "@tool\n",
    "def perform_calculation(expression: str) -> str:\n",
    "    \"\"\"Useful for when you need to do calculations.\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating: {str(e)}\"\n",
    "\n",
    "search = TavilySearchResults(max_results=5)\n",
    "#################################################################\n",
    "model = \"qwen2.5:3b-instruct\"\n",
    "model = \"qwen2.5:7b-instruct\"\n",
    "model = \"qwen2.5:14b-instruct\"\n",
    "model = \"qwen2.5:32b-instruct\"\n",
    "\n",
    "model = \"qwen3:8b\"\n",
    "# model = \"qwen3:14b\"\n",
    "# model = \"qwen3:32b\"\n",
    "\n",
    "# model = \"qwen2.5-coder:32b-instruct-q5_K_M\"\n",
    "# model = \"qwen2.5-coder:14b\"\n",
    "# model =\"mistral-small3.1\"\n",
    "# # model = \"cogito:32b\"\n",
    "# model = \"llama3.3:70b-instruct-q4_K_S\"\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=model, temperature=0.1, max_tokens=512)\n",
    "\n",
    "tools =[perform_calculation, TavilySearchResults(max_results=5)]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "#################################################################\n",
    "response = llm_with_tools.invoke(\"hello\")\n",
    "print_response(response)\n",
    "\n",
    "response= llm_with_tools.invoke(\"Tell me about today temperature at hochiminh city\")\n",
    "print_response(response)\n",
    "    \n",
    "\n",
    "response = llm_with_tools.invoke(\"tell me 2 * 4/90\")\n",
    "print_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b8f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b9171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
