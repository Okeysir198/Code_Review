{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4ad83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "content: Hello! How can I assist you today?\n",
      "additional_kwargs: {}\n",
      "response_metadata: {'model': 'qwen2.5:14b-instruct', 'created_at': '2025-05-27T08:57:00.972174511Z', 'done': True, 'done_reason': 'stop', 'total_duration': 133708751, 'load_duration': 9999957, 'prompt_eval_count': 239, 'prompt_eval_duration': 25197431, 'eval_count': 10, 'eval_duration': 95903555, 'model_name': 'qwen2.5:14b-instruct'}\n",
      "type: ai\n",
      "name: None\n",
      "id: run--ad3349cb-3e92-40e1-8cac-486945ecafd4-0\n",
      "example: False\n",
      "tool_calls: []\n",
      "invalid_tool_calls: []\n",
      "usage_metadata: {'input_tokens': 239, 'output_tokens': 10, 'total_tokens': 249}\n",
      "********************\n",
      "content: \n",
      "additional_kwargs: {}\n",
      "response_metadata: {'model': 'qwen2.5:14b-instruct', 'created_at': '2025-05-27T08:57:01.923899441Z', 'done': True, 'done_reason': 'stop', 'total_duration': 950310761, 'load_duration': 7326548, 'prompt_eval_count': 248, 'prompt_eval_duration': 10519186, 'eval_count': 105, 'eval_duration': 929872138, 'model_name': 'qwen2.5:14b-instruct'}\n",
      "type: ai\n",
      "name: None\n",
      "id: run--e055683e-110e-4970-81b6-01685e0e6625-0\n",
      "example: False\n",
      "tool_calls: [{'name': 'tavily_search_results_json', 'args': {'query': 'today temperature in ho chi minh city'}, 'id': '47d0c1ed-1f33-410b-8b8b-8ab12f8f13be', 'type': 'tool_call'}]\n",
      "invalid_tool_calls: []\n",
      "usage_metadata: {'input_tokens': 248, 'output_tokens': 105, 'total_tokens': 353}\n",
      "********************\n",
      "content: \n",
      "additional_kwargs: {}\n",
      "response_metadata: {'model': 'qwen2.5:14b-instruct', 'created_at': '2025-05-27T08:57:02.271741866Z', 'done': True, 'done_reason': 'stop', 'total_duration': 346671775, 'load_duration': 7198010, 'prompt_eval_count': 248, 'prompt_eval_duration': 10457652, 'eval_count': 37, 'eval_duration': 326574228, 'model_name': 'qwen2.5:14b-instruct'}\n",
      "type: ai\n",
      "name: None\n",
      "id: run--fa594ae6-80d1-4c58-8158-a7635eee32ba-0\n",
      "example: False\n",
      "tool_calls: [{'name': 'perform_calculation', 'args': {'expression': '2 * 4 / 90'}, 'id': 'f28c7dce-5437-4166-bc60-b632fdd95d70', 'type': 'tool_call'}]\n",
      "invalid_tool_calls: []\n",
      "usage_metadata: {'input_tokens': 248, 'output_tokens': 37, 'total_tokens': 285}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "def print_response(response):\n",
    "    print(\"*\"*20)\n",
    "    for k, v in response.__dict__.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        # if k =='content' or k == 'tool_calls':\n",
    "        #     print(f\"{k}: {v}\")\n",
    "\n",
    "@tool\n",
    "def perform_calculation(expression: str) -> str:\n",
    "    \"\"\"Useful for when you need to do calculations.\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating: {str(e)}\"\n",
    "\n",
    "search = TavilySearchResults(max_results=5)\n",
    "#################################################################\n",
    "model = \"qwen2.5:3b-instruct\"\n",
    "model = \"qwen2.5:7b-instruct\"\n",
    "model = \"qwen2.5:14b-instruct\"\n",
    "# model = \"qwen2.5:32b-instruct\"\n",
    "\n",
    "# model = \"qwen3:8b\"\n",
    "# model = \"qwen3:14b\"\n",
    "# model = \"qwen3:32b\"\n",
    "\n",
    "# model = \"qwen2.5-coder:32b-instruct-q5_K_M\"\n",
    "# model = \"qwen2.5-coder:14b\"\n",
    "# model =\"mistral-small3.1\"\n",
    "# # model = \"cogito:32b\"\n",
    "# model = \"llama3.3:70b-instruct-q4_K_S\"\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=model, temperature=0.1, max_tokens=512)\n",
    "\n",
    "tools =[perform_calculation, TavilySearchResults(max_results=5)]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "#################################################################\n",
    "response = llm_with_tools.invoke(\"hello\")\n",
    "print_response(response)\n",
    "\n",
    "response= llm_with_tools.invoke(\"Tell me about today temperature at hochiminh city\")\n",
    "print_response(response)\n",
    "    \n",
    "\n",
    "response = llm_with_tools.invoke(\"tell me 2 * 4/90\")\n",
    "print_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b8f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b9171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
